# This is the single source of truth for production deployment.
# Run with: docker compose -f docker-compose.prod.yml up -d

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

services:
  # --- TRADING CORE ---
  executor:
    build:
      context: .
      dockerfile: Dockerfile.rust
      args:
        SERVICE_NAME: executor
    container_name: executor
    restart: unless-stopped
    logging: *default-logging
    volumes:
      - ./shared:/app/shared
    environment:
      - RUST_LOG=info
      - PAPER_TRADING_MODE=${PAPER_TRADING_MODE}
    deploy:
      resources: { limits: { cpus: '2.0', memory: 4G }, reservations: { cpus: '1.0', memory: 2G } }
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/metrics"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - backend

  autonomous_allocator:
    build:
      context: .
      dockerfile: Dockerfile.python
      args:
        SERVICE_NAME: autonomous_allocator
        SERVICE_DIR: .
    container_name: autonomous_allocator
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  position_manager:
    build:
      context: .
      dockerfile: Dockerfile.rust
      args:
        SERVICE_NAME: position_manager
    container_name: position_manager
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  risk_guardian:
    build:
      context: .
      dockerfile: Dockerfile.rust
      args:
        SERVICE_NAME: risk_guardian
    container_name: risk_guardian
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  wallet_guard:
    build:
      context: .
      dockerfile: Dockerfile.rust
      args:
        SERVICE_NAME: wallet_guard
    container_name: wallet_guard
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  signer:
    build:
      context: .
      dockerfile: Dockerfile.rust
      args:
        SERVICE_NAME: signer
    container_name: signer
    restart: unless-stopped
    logging: *default-logging
    volumes:
      - ./my_wallet.json:/home/appuser/my_wallet.json:ro
      - ./jito_auth_key.json:/home/appuser/jito_auth_key.json:ro
    ports:
      - "8989:8989"
    networks:
      - backend

  # --- DATA PIPELINE ---
  helius_rpc_price_consumer:
    build:
      context: .
      dockerfile: Dockerfile.python
      args:
        SERVICE_NAME: helius_rpc_price_consumer
        SERVICE_DIR: data_consumers
    container_name: helius_rpc_price_consumer
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  social_consumer:
    build:
      context: .
      dockerfile: Dockerfile.python
      args:
        SERVICE_NAME: social_consumer
        SERVICE_DIR: data_consumers
    container_name: social_consumer
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  onchain_consumer:
    build:
      context: .
      dockerfile: Dockerfile.python
      args:
        SERVICE_NAME: onchain_consumer
        SERVICE_DIR: data_consumers
    container_name: onchain_consumer
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  # --- UI & FACTORY ---
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile.python
      args:
        SERVICE_NAME: app
        SERVICE_DIR: dashboard
    container_name: dashboard
    restart: unless-stopped
    logging: *default-logging
    ports:
      - "8080:5000"
    networks:
      - backend

  strategy_factory:
    build:
      context: .
      dockerfile: Dockerfile.python
      args:
        SERVICE_NAME: factory
        SERVICE_DIR: strategy_factory
    container_name: strategy_factory
    restart: unless-stopped
    logging: *default-logging
    networks:
      - backend

  # --- INFRASTRUCTURE ---
  redis:
    image: redis:7.2-alpine
    container_name: redis
    restart: unless-stopped
    logging: *default-logging
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - backend

  nginx:
    image: nginx:alpine
    container_name: nginx
    restart: unless-stopped
    logging: *default-logging
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - dashboard
    networks:
      - backend

  # --- OBSERVABILITY STACK ---
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    logging: *default-logging
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus.rules.yml:/etc/prometheus/prometheus.rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    networks:
      - backend
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    logging: *default-logging
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - monitoring
    depends_on:
      - prometheus

volumes:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  backend:
    driver: bridge
  monitoring:
    driver: bridge
